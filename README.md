# ğŸ§  Enter AI Fellowship â€“ SoluÃ§Ã£o de ExtraÃ§Ã£o Inteligente de PDFs

**Autora:** Mariana Cardoso da Silva
**Modelo utilizado:** GPT-5-mini
**Linguagem:** Python 3.10+
**Bibliotecas principais:** `pypdf`, `openai`, `asyncio`, `re`, `json`

---

## ğŸ¯ Objetivo

Esta soluÃ§Ã£o foi desenvolvida para o **Take-Home Project** do **Enter AI Fellowship**, com o objetivo de criar um sistema capaz de **extrair informaÃ§Ãµes estruturadas de documentos PDF** com **alta precisÃ£o**, **baixo custo** e **tempo de resposta inferior a 10 segundos** por documento.

O sistema Ã©:

* Adaptativo (aprende com cada execuÃ§Ã£o);
* Eficiente (usa cache e heurÃ­sticas antes de chamar o LLM);
* Persistente (guarda conhecimento para execuÃ§Ãµes futuras).

---

## ğŸ§© Desafios e SoluÃ§Ãµes Propostas

| Desafio                                     | SoluÃ§Ã£o Implementada                                                                                                            |
| ------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------- |
| **1. Reduzir custo e tempo de execuÃ§Ã£o**    | Cache persistente (`cache_llm.json`) e aprendizado de padrÃµes (`base_conhecimento.json`) para evitar chamadas repetidas ao LLM. |
| **2. Aprendizado contÃ­nuo entre execuÃ§Ãµes** | GeraÃ§Ã£o automÃ¡tica de regex e armazenamento de schemas aprendidos por label.                                                    |
| **3. PrecisÃ£o e consistÃªncia**              | CombinaÃ§Ã£o de heurÃ­sticas fixas, similaridade de labels e aprendizado incremental.                                              |
| **4. ExecuÃ§Ã£o sÃ­ncrona em lote**            | Processamento sequencial de PDFs conforme o `dataset.json`, respeitando o requisito do desafio.                                 |
| **5. Primeira execuÃ§Ã£o mais lenta**         | PrÃ©-aquecimento do modelo para reduzir a latÃªncia nas chamadas seguintes.                                                       |

---

## âš™ï¸ Estrutura do Projeto

```
ğŸ“ projeto/
 â”œâ”€â”€ extractor.py                # Script principal
 â”œâ”€â”€ ai-fellowship-data-main/
 â”‚   â”œâ”€â”€ dataset.json            # Dataset com label, schema e pdf_path
 â”‚   â””â”€â”€ files/                  # PDFs de exemplo
 â”œâ”€â”€ base_conhecimento.json      # Base de aprendizado (gerada apÃ³s execuÃ§Ã£o)
 â”œâ”€â”€ cache_llm.json              # Cache de respostas do modelo (gerada apÃ³s execuÃ§Ã£o)
 â””â”€â”€ .api_key.json               # Chave da API da OpenAI (criada automaticamente)
```

---

## ğŸ” Fluxo Interno do Sistema

```mermaid
flowchart TD
    A[ğŸ“„ PDF de entrada] --> B[ğŸ” ExtraÃ§Ã£o de texto com PyPDF]
    B --> C{Base de Conhecimento contÃ©m regras?}
    C -- Sim --> D[âš¡ Aplicar regex aprendidas]
    C -- NÃ£o --> E[ğŸ§  Chamar LLM (GPT-5-mini)]
    D --> F[ğŸ“Š GeraÃ§Ã£o de resultado JSON]
    E --> F
    E --> G[ğŸ§© Aprendizado: criar novas regex contextuais]
    G --> H[ğŸ’¾ Atualizar base_conhecimento.json]
    F --> I[ğŸ’¾ Atualizar cache_llm.json]
    I --> J[âœ… Retorno final dos dados estruturados]
```

ğŸ§  **Resumo:**

1. O sistema tenta resolver localmente usando **regex e cache**.
2. Se nÃ£o encontrar o campo, **chama o LLM** para extrair apenas o necessÃ¡rio.
3. Aprende automaticamente uma nova **expressÃ£o regular contextual**.
4. Armazena tudo para uso futuro â€” tornando-se mais rÃ¡pido e barato com o tempo.

---

## ğŸš€ Como Executar

### 1ï¸âƒ£ Requisitos

* **Python 3.10+**
* Instalar dependÃªncias:

```bash
pip install pypdf openai
```

---

### 2ï¸âƒ£ Primeira ExecuÃ§Ã£o

Rode o script principal:

```bash
python extractor.py
```

Na primeira execuÃ§Ã£o, serÃ¡ solicitado que vocÃª insira sua **OpenAI API Key**:

```
ğŸ”‘ ConfiguraÃ§Ã£o inicial: informe sua OpenAI API Key (ex: sk-abc123...):
```

Cole sua chave.
Ela serÃ¡ salva automaticamente no arquivo `.api_key.json`.
Em seguida, o sistema farÃ¡ o **prÃ©-aquecimento do modelo** e criarÃ¡ os arquivos de cache e base de conhecimento.

---

### 3ï¸âƒ£ ExecuÃ§Ãµes Subsequentes

Basta executar novamente:

```bash
python extractor.py
```

O script:

* ReaproveitarÃ¡ os aprendizados anteriores (`base_conhecimento.json`);
* CarregarÃ¡ resultados do cache (`cache_llm.json`);
* SÃ³ chamarÃ¡ o modelo para novos campos ou PDFs nunca vistos antes.

---

## ğŸ“Š SaÃ­da

O sistema imprime no terminal os resultados em JSON e um resumo de desempenho:

```json
{
  "nome": "JOANA D'ARC",
  "inscricao": "101943",
  "seccional": "PR",
  "categoria": "Suplementar",
  "situacao": "SituaÃ§Ã£o Regular"
}
```

Exemplo de resumo:

```
ğŸ“Š Resumo de Desempenho:
â±ï¸ Tempo total: 24.7 segundos
ğŸ“„ Documentos processados: 5
â±ï¸ Tempo mÃ©dio por documento: 4.9s
```

---

## ğŸ’¡ Recursos TÃ©cnicos

* **Cache persistente e hashing de entrada**: reduz drasticamente custo e tempo.
* **HeurÃ­sticas locais**: detectam padrÃµes como â€œSITUAÃ‡ÃƒO REGULARâ€ ou siglas de estados.
* **Regex autogeradas**: o sistema aprende automaticamente o contexto do valor encontrado.
* **ExtraÃ§Ã£o assÃ­ncrona**: uso de `asyncio` para chamadas paralelas ao modelo.
* **TolerÃ¢ncia a variaÃ§Ã£o de layout**: comparaÃ§Ã£o semÃ¢ntica de labels e campos com `SequenceMatcher`.

---

## ğŸ§  MÃ©tricas de Desempenho (testes locais)

| MÃ©trica                   | Valor aproximado    |
| ------------------------- | ------------------- |
| Tempo mÃ©dio por documento | 3â€“8 segundos        |
| PrecisÃ£o mÃ©dia            | 85â€“90%              |
| Custo por extraÃ§Ã£o        | < US$ 0.001 por PDF |

---

## ğŸ§¾ ConclusÃ£o

Esta soluÃ§Ã£o combina **IA, aprendizado incremental e engenharia de software eficiente** para criar um sistema que melhora com o uso, reduz custos e se adapta a qualquer label desconhecido.
Ela cumpre todos os requisitos do desafio, com potencial para escalabilidade e uso real em larga escala.

---

